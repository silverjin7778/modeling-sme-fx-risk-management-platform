{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dbc53-7247-400b-97f0-5b9c51dbbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# ë°ì´í„° ìˆ˜ì§‘\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def euro_indicator():\n",
    "    tickers = {\n",
    "        \"DAX\": \"^GDAXI\",\n",
    "        \"EUROSTOXX50\": \"^STOXX50E\",\n",
    "        \"CAC\": \"^FCHI\"\n",
    "    }\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for name, symbol in tickers.items():\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        df = ticker.history(period=\"25y\", interval=\"1d\")\n",
    "        df = df.reset_index()\n",
    "        \n",
    "    \n",
    "        df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "        df = df.rename(columns={\n",
    "            \"Open\": f\"{name}_Open\",\n",
    "            \"High\": f\"{name}_High\",\n",
    "            \"Low\": f\"{name}_Low\",\n",
    "            \"Close\": f\"{name}_Close\"\n",
    "        })\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.tz_localize(None)\n",
    "        data_list.append(df)\n",
    "    \n",
    "    df_merged = data_list[0]\n",
    "    for df in data_list[1:]:\n",
    "        df['Date']=pd.to_datetime(df['Date'])\n",
    "        df_merged = pd.merge(df_merged, df, on=\"Date\", how=\"inner\")\n",
    "    \n",
    "    df_merged['Date'] = pd.to_datetime(df_merged['Date']).dt.strftime('%Y-%m-%d')\n",
    "    df_merged['Date'] = pd.to_datetime(df_merged['Date'])\n",
    "    return df_merged\n",
    "\n",
    "import cloudpickle\n",
    "with open(\"euro_indicator.pkl\", \"wb\") as f:\n",
    "    cloudpickle.dump(euro_indicator, f)\n",
    "\n",
    "euro_indi_df=euro_indicator()\n",
    "\n",
    "def real_times(symbol):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    df = ticker.history(period=f\"25y\", interval=\"1d\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "    df.columns = [f\"{col}\" for col in df.columns]\n",
    "    df[\"Date\"] = df.index.date\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # ë³€ë™ëŸ‰ ê³„ì‚°\n",
    "    df[\"Change\"] = df[\"Close\"].diff()\n",
    "    \n",
    "    df['Date']=pd.to_datetime(df['Date'],format='%Y-%m-%d')\n",
    "    \n",
    "    df=df.reindex(columns=['Date','Close','Open','High','Low','Change'])\n",
    "    return df\n",
    "\n",
    "import cloudpickle\n",
    "with open(\"real_times.pkl\", \"wb\") as f:\n",
    "    cloudpickle.dump(real_times, f)\n",
    "\n",
    "euro_df=real_times('EURKRW=X')\n",
    "\n",
    "all_df=pd.merge(euro_indi_df,euro_df,on='Date',how='inner')\n",
    "\n",
    "df_base=all_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# í•˜ë£¨ ì˜ˆì¸¡\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 2. ë°ì´í„° ì¤€ë¹„\n",
    "df = df_base.copy()  # ê¸°ì¡´ df_baseë¥¼ ìœ ì§€\n",
    "df = df.sort_values('Date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['target'] = df['Close'].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3. í”¼ì²˜, íƒ€ê²Ÿ ì„¤ì •\n",
    "drop_cols = ['Date', 'ê¸°ì¤€ë…„ì›”', 'return', 'return_future', 'target', 'next_day_close']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "y = df['target'].values\n",
    "\n",
    "# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train_raw, X_test_raw = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train_raw, y_test_raw = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler_X = MinMaxScaler().fit(X_train_raw)\n",
    "X_train_scaled = scaler_X.transform(X_train_raw)\n",
    "X_test_scaled = scaler_X.transform(X_test_raw)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(y_train_raw.reshape(-1, 1))\n",
    "y_train_scaled = scaler_y.transform(y_train_raw.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test_raw.reshape(-1, 1))\n",
    "\n",
    "# 6. ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "def make_sequence(X, y, seq_len):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X[i:i+seq_len])\n",
    "        y_seq.append(y[i+seq_len])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_len = 20\n",
    "X_train_seq, y_train_seq = make_sequence(X_train_scaled, y_train_scaled, seq_len)\n",
    "X_test_seq, y_test_seq = make_sequence(X_test_scaled, y_test_scaled, seq_len)\n",
    "\n",
    "X_train_flat = X_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "X_test_flat  = X_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "y_train_flat = y_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "y_test_flat  = y_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "\n",
    "# 7. ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡\n",
    "## XGBoost\n",
    "model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "model_xgb.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_xgb = scaler_y.inverse_transform(model_xgb.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "## LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(128, input_shape=(seq_len, X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stop = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, validation_split=0.2,\n",
    "               callbacks=[early_stop], verbose=0)\n",
    "y_pred_lstm = scaler_y.inverse_transform(model_lstm.predict(X_test_seq)).reshape(-1)\n",
    "\n",
    "## RandomForest\n",
    "model_rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_rf.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_rf = scaler_y.inverse_transform(model_rf.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# 8. ì‹¤ì œê°’ ë³µì›\n",
    "y_true = scaler_y.inverse_transform(y_test_seq).reshape(-1)\n",
    "\n",
    "# 9. ì„±ëŠ¥ ì¶œë ¥\n",
    "for name, pred in zip(['XGBoost', 'LSTM', 'RandomForest'],\n",
    "                      [y_pred_xgb, y_pred_lstm, y_pred_rf]):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "    mae = mean_absolute_error(y_true, pred)\n",
    "    r2 = r2_score(y_true, pred)\n",
    "    print(f\"ğŸ“Š {name}\")\n",
    "    print(f\"    MAE:  {mae:.4f}\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    RÂ²:   {r2:.4f}\")\n",
    "\n",
    "# 10. ì‹œê°í™”\n",
    "date_test = df['Date'].iloc[seq_len + split_idx:].reset_index(drop=True)\n",
    "n = min(len(date_test), len(y_true), len(y_pred_xgb), len(y_pred_lstm), len(y_pred_rf))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(date_test[:n], y_true[:n], label='ì‹¤ì œ ì¢…ê°€', linewidth=2)\n",
    "plt.plot(date_test[:n], y_pred_xgb[:n], label='XGBoost ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_lstm[:n], label='LSTM ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_rf[:n], label='RandomForest ì˜ˆì¸¡', linestyle='--')\n",
    "plt.title(\"ëª¨ë¸ë³„ í•˜ë£¨ ë’¤ ì¢…ê°€ ì˜ˆì¸¡ ë¹„êµ\")\n",
    "plt.xlabel(\"ë‚ ì§œ\")\n",
    "plt.ylabel(\"Close\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model_xgb, 'euro_í•˜ë£¨.pkl')\n",
    "joblib.dump(scaler_X, 'euro_scaler_X_í•˜ë£¨.pkl')\n",
    "joblib.dump(scaler_y, 'euro_scaler_y_í•˜ë£¨.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ì¼ì£¼ì¼ ì˜ˆì¸¡\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 2. ë°ì´í„° ì¤€ë¹„\n",
    "df = df_base.copy()  # ê¸°ì¡´ df_baseë¥¼ ìœ ì§€\n",
    "df = df.sort_values('Date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['target'] = df['Close'].shift(-5)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3. í”¼ì²˜, íƒ€ê²Ÿ ì„¤ì •\n",
    "drop_cols = ['Date', 'ê¸°ì¤€ë…„ì›”', 'return', 'return_future', 'target', 'next_day_close']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "y = df['target'].values\n",
    "\n",
    "# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train_raw, X_test_raw = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train_raw, y_test_raw = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler_X = MinMaxScaler().fit(X_train_raw)\n",
    "X_train_scaled = scaler_X.transform(X_train_raw)\n",
    "X_test_scaled = scaler_X.transform(X_test_raw)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(y_train_raw.reshape(-1, 1))\n",
    "y_train_scaled = scaler_y.transform(y_train_raw.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test_raw.reshape(-1, 1))\n",
    "\n",
    "# 6. ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "def make_sequence(X, y, seq_len):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X[i:i+seq_len])\n",
    "        y_seq.append(y[i+seq_len])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_len = 20\n",
    "X_train_seq, y_train_seq = make_sequence(X_train_scaled, y_train_scaled, seq_len)\n",
    "X_test_seq, y_test_seq = make_sequence(X_test_scaled, y_test_scaled, seq_len)\n",
    "\n",
    "X_train_flat = X_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "X_test_flat  = X_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "y_train_flat = y_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "y_test_flat  = y_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "\n",
    "# 7. ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡\n",
    "## XGBoost\n",
    "model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "model_xgb.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_xgb = scaler_y.inverse_transform(model_xgb.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "## LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(128, input_shape=(seq_len, X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stop = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, validation_split=0.2,\n",
    "               callbacks=[early_stop], verbose=0)\n",
    "y_pred_lstm = scaler_y.inverse_transform(model_lstm.predict(X_test_seq)).reshape(-1)\n",
    "\n",
    "## RandomForest\n",
    "model_rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_rf.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_rf = scaler_y.inverse_transform(model_rf.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# 8. ì‹¤ì œê°’ ë³µì›\n",
    "y_true = scaler_y.inverse_transform(y_test_seq).reshape(-1)\n",
    "\n",
    "# 9. ì„±ëŠ¥ ì¶œë ¥\n",
    "for name, pred in zip(['XGBoost', 'LSTM', 'RandomForest'],\n",
    "                      [y_pred_xgb, y_pred_lstm, y_pred_rf]):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "    mae = mean_absolute_error(y_true, pred)\n",
    "    r2 = r2_score(y_true, pred)\n",
    "    print(f\"ğŸ“Š {name}\")\n",
    "    print(f\"    MAE:  {mae:.4f}\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    RÂ²:   {r2:.4f}\")\n",
    "\n",
    "# 10. ì‹œê°í™”\n",
    "date_test = df['Date'].iloc[seq_len + split_idx:].reset_index(drop=True)\n",
    "n = min(len(date_test), len(y_true), len(y_pred_xgb), len(y_pred_lstm), len(y_pred_rf))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(date_test[:n], y_true[:n], label='ì‹¤ì œ ì¢…ê°€', linewidth=2)\n",
    "plt.plot(date_test[:n], y_pred_xgb[:n], label='XGBoost ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_lstm[:n], label='LSTM ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_rf[:n], label='RandomForest ì˜ˆì¸¡', linestyle='--')\n",
    "plt.title(\"ëª¨ë¸ë³„ ì¼ì£¼ì¼ ë’¤ ì¢…ê°€ ì˜ˆì¸¡ ë¹„êµ\")\n",
    "plt.xlabel(\"ë‚ ì§œ\")\n",
    "plt.ylabel(\"Close\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model_lstm, 'euro_ì¼ì£¼ì¼.pkl')\n",
    "joblib.dump(scaler_X, 'euro_scaler_X_ì¼ì£¼ì¼.pkl')\n",
    "joblib.dump(scaler_y, 'euro_scaler_y_ì¼ì£¼ì¼.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# í•œë‹¬ ì˜ˆì¸¡\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 2. ë°ì´í„° ì¤€ë¹„\n",
    "df = df_base.copy()  # ê¸°ì¡´ df_baseë¥¼ ìœ ì§€\n",
    "df = df.sort_values('Date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['target'] = df['Close'].shift(-20)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3. í”¼ì²˜, íƒ€ê²Ÿ ì„¤ì •\n",
    "drop_cols = ['Date', 'ê¸°ì¤€ë…„ì›”', 'return', 'return_future', 'target', 'next_day_close']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "y = df['target'].values\n",
    "\n",
    "# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train_raw, X_test_raw = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train_raw, y_test_raw = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler_X = MinMaxScaler().fit(X_train_raw)\n",
    "X_train_scaled = scaler_X.transform(X_train_raw)\n",
    "X_test_scaled = scaler_X.transform(X_test_raw)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(y_train_raw.reshape(-1, 1))\n",
    "y_train_scaled = scaler_y.transform(y_train_raw.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test_raw.reshape(-1, 1))\n",
    "\n",
    "# 6. ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "def make_sequence(X, y, seq_len):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X[i:i+seq_len])\n",
    "        y_seq.append(y[i+seq_len])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_len = 20\n",
    "X_train_seq, y_train_seq = make_sequence(X_train_scaled, y_train_scaled, seq_len)\n",
    "X_test_seq, y_test_seq = make_sequence(X_test_scaled, y_test_scaled, seq_len)\n",
    "\n",
    "X_train_flat = X_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "X_test_flat  = X_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "y_train_flat = y_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "y_test_flat  = y_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "\n",
    "# 7. ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡\n",
    "## XGBoost\n",
    "model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "model_xgb.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_xgb = scaler_y.inverse_transform(model_xgb.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "## LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(128, input_shape=(seq_len, X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stop = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, validation_split=0.2,\n",
    "               callbacks=[early_stop], verbose=0)\n",
    "y_pred_lstm = scaler_y.inverse_transform(model_lstm.predict(X_test_seq)).reshape(-1)\n",
    "\n",
    "## RandomForest\n",
    "model_rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_rf.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_rf = scaler_y.inverse_transform(model_rf.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# 8. ì‹¤ì œê°’ ë³µì›\n",
    "y_true = scaler_y.inverse_transform(y_test_seq).reshape(-1)\n",
    "\n",
    "# 9. ì„±ëŠ¥ ì¶œë ¥\n",
    "for name, pred in zip(['XGBoost', 'LSTM', 'RandomForest'],\n",
    "                      [y_pred_xgb, y_pred_lstm, y_pred_rf]):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "    mae = mean_absolute_error(y_true, pred)\n",
    "    r2 = r2_score(y_true, pred)\n",
    "    print(f\"ğŸ“Š {name}\")\n",
    "    print(f\"    MAE:  {mae:.4f}\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    RÂ²:   {r2:.4f}\")\n",
    "\n",
    "# 10. ì‹œê°í™”\n",
    "date_test = df['Date'].iloc[seq_len + split_idx:].reset_index(drop=True)\n",
    "n = min(len(date_test), len(y_true), len(y_pred_xgb), len(y_pred_lstm), len(y_pred_rf))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(date_test[:n], y_true[:n], label='ì‹¤ì œ ì¢…ê°€', linewidth=2)\n",
    "plt.plot(date_test[:n], y_pred_xgb[:n], label='XGBoost ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_lstm[:n], label='LSTM ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_rf[:n], label='RandomForest ì˜ˆì¸¡', linestyle='--')\n",
    "plt.title(\"ëª¨ë¸ë³„ í•œë‹¬ ë’¤ ì¢…ê°€ ì˜ˆì¸¡ ë¹„êµ\")\n",
    "plt.xlabel(\"ë‚ ì§œ\")\n",
    "plt.ylabel(\"Close\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model_rf, 'euro_í•œë‹¬.pkl')\n",
    "joblib.dump(scaler_X, 'euro_scaler_X_í•œë‹¬.pkl')\n",
    "joblib.dump(scaler_y, 'euro_scaler_y_í•œë‹¬.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ì„¸ë‹¬ ì˜ˆì¸¡\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 2. ë°ì´í„° ì¤€ë¹„\n",
    "df = df_base.copy()  # ê¸°ì¡´ df_baseë¥¼ ìœ ì§€\n",
    "df = df.sort_values('Date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['target'] = df['Close'].shift(-60)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 3. í”¼ì²˜, íƒ€ê²Ÿ ì„¤ì •\n",
    "drop_cols = ['Date', 'ê¸°ì¤€ë…„ì›”', 'return', 'return_future', 'target', 'next_day_close']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "y = df['target'].values\n",
    "\n",
    "# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train_raw, X_test_raw = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train_raw, y_test_raw = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler_X = MinMaxScaler().fit(X_train_raw)\n",
    "X_train_scaled = scaler_X.transform(X_train_raw)\n",
    "X_test_scaled = scaler_X.transform(X_test_raw)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(y_train_raw.reshape(-1, 1))\n",
    "y_train_scaled = scaler_y.transform(y_train_raw.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test_raw.reshape(-1, 1))\n",
    "\n",
    "# 6. ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "def make_sequence(X, y, seq_len):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X[i:i+seq_len])\n",
    "        y_seq.append(y[i+seq_len])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_len = 20\n",
    "X_train_seq, y_train_seq = make_sequence(X_train_scaled, y_train_scaled, seq_len)\n",
    "X_test_seq, y_test_seq = make_sequence(X_test_scaled, y_test_scaled, seq_len)\n",
    "\n",
    "X_train_flat = X_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "X_test_flat  = X_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "y_train_flat = y_train_scaled[seq_len:][:len(X_train_seq)]\n",
    "y_test_flat  = y_test_scaled[seq_len:][:len(X_test_seq)]\n",
    "\n",
    "# 7. ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡\n",
    "## XGBoost\n",
    "model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    "model_xgb.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_xgb = scaler_y.inverse_transform(model_xgb.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "## LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(128, input_shape=(seq_len, X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stop = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, validation_split=0.2,\n",
    "               callbacks=[early_stop], verbose=0)\n",
    "y_pred_lstm = scaler_y.inverse_transform(model_lstm.predict(X_test_seq)).reshape(-1)\n",
    "\n",
    "## RandomForest\n",
    "model_rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model_rf.fit(X_train_flat, y_train_flat.ravel())\n",
    "y_pred_rf = scaler_y.inverse_transform(model_rf.predict(X_test_flat).reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# 8. ì‹¤ì œê°’ ë³µì›\n",
    "y_true = scaler_y.inverse_transform(y_test_seq).reshape(-1)\n",
    "\n",
    "# 9. ì„±ëŠ¥ ì¶œë ¥\n",
    "for name, pred in zip(['XGBoost', 'LSTM', 'RandomForest'],\n",
    "                      [y_pred_xgb, y_pred_lstm, y_pred_rf]):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "    mae = mean_absolute_error(y_true, pred)\n",
    "    r2 = r2_score(y_true, pred)\n",
    "    print(f\"ğŸ“Š {name}\")\n",
    "    print(f\"    MAE:  {mae:.4f}\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    RÂ²:   {r2:.4f}\")\n",
    "\n",
    "# 10. ì‹œê°í™”\n",
    "date_test = df['Date'].iloc[seq_len + split_idx:].reset_index(drop=True)\n",
    "n = min(len(date_test), len(y_true), len(y_pred_xgb), len(y_pred_lstm), len(y_pred_rf))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(date_test[:n], y_true[:n], label='ì‹¤ì œ ì¢…ê°€', linewidth=2)\n",
    "plt.plot(date_test[:n], y_pred_xgb[:n], label='XGBoost ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_lstm[:n], label='LSTM ì˜ˆì¸¡', linestyle='--')\n",
    "plt.plot(date_test[:n], y_pred_rf[:n], label='RandomForest ì˜ˆì¸¡', linestyle='--')\n",
    "plt.title(\"ëª¨ë¸ë³„ ì„¸ë‹¬ ë’¤ ì¢…ê°€ ì˜ˆì¸¡ ë¹„êµ\")\n",
    "plt.xlabel(\"ë‚ ì§œ\")\n",
    "plt.ylabel(\"Close\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model_lstm, 'euro_ì„¸ë‹¬.pkl')\n",
    "joblib.dump(scaler_X, 'euro_scaler_X_ì„¸ë‹¬.pkl')\n",
    "joblib.dump(scaler_y, 'euro_scaler_y_ì„¸ë‹¬.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
